{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarthakAgase/AI-Speech-Emotion-Detection/blob/main/ML_Text_To_Emotion_with_all_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwK5-9FIB-lu"
      },
      "source": [
        "# Emotion Detection Models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaInD7MxYdJ8"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1kiO9kACE6s"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcIBhxAaFnHp",
        "outputId": "7bae3ee3-4419-4781-e88a-8d4f7db23dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re, nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.remove(\"no\")\n",
        "stop_words.remove(\"not\")\n",
        "stop_words.remove(\"nor\")\n",
        "stop_words = [x.lower() for x in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdreXsRUJVm7",
        "outputId": "418bd546-777b-4720-9d2e-c36158d0a53a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8laN2NPRcH6i"
      },
      "source": [
        "### Pre-Defined Dictionary Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UH9bzPAabHzz"
      },
      "outputs": [],
      "source": [
        "contractions = {\n",
        "        \"ai\\snot\": \"am not\",\n",
        "        \"wo\\snot\": \"will not\",\n",
        "        \"would\\snot\": \"would not\",\n",
        "        \"should\\snot\": \"should not\",\n",
        "        \"isn\\snot\": \"is not\",\n",
        "        \"aren\\snot\": \"are not\",\n",
        "        \"wasn\\snot\": \"was not\",\n",
        "        \"weren\\snot\": \"were not\",\n",
        "        \"haven\\snot\": \"have not\",\n",
        "        \"hasn\\snot\": \"has not\",\n",
        "        \"hadn\\snot\": \"had not\",\n",
        "        \"don\\snot\": \"do not\",\n",
        "        \"doesn\\snot\": \"does not\",\n",
        "        \"didn\\snot\": \"did not\",\n",
        "        \"can\\snot\": \"can not\",\n",
        "        \"cannot\": \"can not\",\n",
        "        \"couldn\\snot\": \"could not\",\n",
        "        \"shouldn\\snot\": \"should not\",\n",
        "        \"mightn\\snot\": \"might not\",\n",
        "        \"mustn\\snot\": \"must not\",\n",
        "        \"shan\\snot\": \"shall not\",\n",
        "        \"won\\snot\": \"will not\",\n",
        "        \"ain\\snot\": \"am not\",\n",
        "        \"I\\sam\": \"I am\",\n",
        "        \"you\\sare\": \"you are\",\n",
        "        \"he\\sis\": \"he is\",\n",
        "        \"she\\sis\": \"she is\",\n",
        "        \"it\\sis\": \"it is\",\n",
        "        \"we\\sare\": \"we are\",\n",
        "        \"they\\sare\": \"they are\",\n",
        "        \"I\\swould\": \"I would\",\n",
        "        \"you\\swould\": \"you would\",\n",
        "        \"he\\swould\": \"he would\",\n",
        "        \"she\\swould\": \"she would\",\n",
        "        \"it\\swould\": \"it would\",\n",
        "        \"we\\swould\": \"we would\",\n",
        "        \"they\\swould\": \"they would\",\n",
        "        \"I\\scould\": \"I could\",\n",
        "        \"you\\scould\": \"you could\",\n",
        "        \"he\\scould\": \"he could\",\n",
        "        \"she\\scould\": \"she could\",\n",
        "        \"it\\scould\": \"it could\",\n",
        "        \"we\\scould\": \"we could\",\n",
        "        \"they\\scould\": \"they could\",\n",
        "        \"I\\shave\": \"I have\",\n",
        "        \"you\\shave\": \"you have\",\n",
        "        \"he\\shas\": \"he has\",\n",
        "        \"she\\shas\": \"she has\",\n",
        "        \"it\\shas\": \"it has\",\n",
        "        \"we\\shave\": \"we have\",\n",
        "        \"they\\shave\": \"they have\",\n",
        "        \"I\\swill\": \"I will\",\n",
        "        \"you\\swill\": \"you will\",\n",
        "        \"he\\swill\": \"he will\",\n",
        "        \"she\\swill\": \"she will\",\n",
        "        \"it\\swill\": \"it will\",\n",
        "        \"we\\swill\": \"we will\",\n",
        "        \"they\\swill\": \"they will\",\n",
        "        \"I\\smust\": \"I must\",\n",
        "        \"you\\smust\": \"you must\",\n",
        "        \"he\\smust\": \"he must\",\n",
        "        \"she\\smust\": \"she must\",\n",
        "        \"it\\smust\": \"it must\",\n",
        "        \"we\\smust\": \"we must\",\n",
        "        \"they\\smust\": \"they must\",\n",
        "        \"I\\sshall\": \"I shall\",\n",
        "        \"you\\sshall\": \"you shall\",\n",
        "        \"he\\sshall\": \"he shall\",\n",
        "        \"she\\sshall\": \"she shall\",\n",
        "        \"it\\sshall\": \"it shall\",\n",
        "        \"we\\sshall\": \"we shall\",\n",
        "        \"they\\sshall\": \"they shall\",\n",
        "        \"haven\\s't\": \"have not\",\n",
        "        \"hasn\\s't\": \"has not\",\n",
        "        \"hadn\\s't\": \"had not\",\n",
        "        \"don\\s't\": \"do not\",\n",
        "        \"doesn\\s't\": \"does not\",\n",
        "        \"didn\\s't\": \"did not\",\n",
        "        \"can\\s't\": \"can not\",\n",
        "        \"cannot\": \"can not\",\n",
        "        \"couldn\\s't\": \"could not\",\n",
        "        \"shouldn\\s't\": \"should not\",\n",
        "        \"mightn\\s't\": \"might not\",\n",
        "        \"mustn\\s't\": \"must not\",\n",
        "        \"shan\\s't\": \"shall not\",\n",
        "        \"won\\s't\": \"will not\",\n",
        "        \"ain\\s't\": \"am not\",\n",
        "        \"aren\\s't\": \"are not\",\n",
        "        \"wasn\\s't\": \"was not\",\n",
        "        \"weren\\s't\": \"were not\",\n",
        "        \"I\\sdidn't\": \"I did not\",\n",
        "        \"you\\sdidn't\": \"you did not\",\n",
        "        \"he\\sdidn't\": \"he did not\",\n",
        "        \"she\\sdidn't\": \"she did not\",\n",
        "        \"it\\sdidn't\": \"it did not\",\n",
        "        \"we\\sdidn't\": \"we did not\",\n",
        "        \"they\\sdidn't\": \"they did not\",\n",
        "        \"I\\scannot\": \"I can not\",\n",
        "        \"you\\scannot\": \"you can not\",\n",
        "        \"he\\scannot\": \"he can not\",\n",
        "        \"she\\scannot\": \"she can not\",\n",
        "        \"it\\scannot\": \"it can not\",\n",
        "        \"we\\scannot\": \"we can not\",\n",
        "        \"they\\scannot\": \"they can not\",\n",
        "        \"I\\swon't\": \"I will not\",\n",
        "        \"you\\swon't\": \"you will not\",\n",
        "        \"he\\swon't\": \"he will not\",\n",
        "        \"she\\swon't\": \"she will not\",\n",
        "        \"it\\swon't\": \"it will not\",\n",
        "        \"we\\swon't\": \"we will not\",\n",
        "        \"they\\swon't\": \"they will not\",\n",
        "        \"I\\shasn't\": \"I has not\",\n",
        "        \"you\\shasn't\": \"you has not\",\n",
        "        \"he\\shasn't\": \"he has not\",\n",
        "        \"she\\shasn't\": \"she has not\",\n",
        "        \"it\\shasn't\": \"it has not\",\n",
        "        \"we\\shasn't\": \"we has not\",\n",
        "        \"they\\shasn't\": \"they has not\"\n",
        "}\n",
        "\n",
        "nots = {\n",
        "    'not sad': 'Happy', 'not bad': 'Happy', 'not boring': 'Happy', 'not wrong': 'Happy', 'not bored': 'Happy',\n",
        "        'not jealous': 'Happy', 'not happy': 'Sad', 'not well': 'Sad', 'not suitable': 'Angry',\n",
        "        'not right': 'Angry', 'not good': 'Sad', 'not excited': 'Angry', 'not funny ': 'Sad', 'not kind': 'Sad',\n",
        "        'not proud': 'Angry', 'not cool': 'Angry', 'not funny': 'Angry', 'not kind': 'Angry', 'not open': 'Angry',\n",
        "        'not safe': 'Fear', 'not enough': 'Empty', 'not know': 'Sad', 'not knowing': 'Sad', 'not believe': 'Angry',\n",
        "        'not believing': 'Angry', 'not understand': 'Sad', 'not understanding': 'Sad', 'no doubt': 'Happy',\n",
        "        'not think': 'Sad', 'not thinking': 'Sad', 'not recognise': 'Sad', 'not recognising': 'Sad',\n",
        "        'not forget': 'Angry', 'not forgetting': 'Angry', 'not remember': 'Sad', 'not remembering': 'Sad',\n",
        "        'not imagine': 'Sad', 'not imagining': 'Sad', 'not mean': 'Sad', 'not meaning': 'Sad',\n",
        "        'not agree': 'Angry', 'not agreeing': 'Sad', 'not disagree': 'Happy', 'not disagreeing': 'Happy',\n",
        "        'not deny': 'Sad', 'not denying': 'Sad', 'not promise': 'Angry', 'not promising': 'Angry',\n",
        "        'not satisfy': 'Sad', 'not satisfying': 'Sad', 'not realise': 'Sad', 'not realising': 'Sad',\n",
        "        'not appear': 'Angry', 'not appearing': 'Angry', 'not please': 'Sad', 'not pleasing': 'Sad',\n",
        "        'not impress': 'Sad', 'not impressing': 'Sad', 'not surprise': 'Sad', 'not surprising': 'Sad',\n",
        "        'not concern': 'Sad', 'not concerning': 'Sad', 'not have': 'Sad', 'not having': 'Sad',\n",
        "        'not own': 'Sad', 'not owning': 'Sad', 'not possess': 'Sad', 'not possessing': 'Sad',\n",
        "        'not lack': 'Sad', 'not lacking': 'Sad', 'not consist': 'Sad', 'not consisting': 'Sad',\n",
        "        'not involve': 'Sad', 'not involving': 'Sad', 'not include': 'Sad', 'not including': 'Sad',\n",
        "        'not contain': 'Sad', 'not containing': 'Sad', 'not love': 'Sad', 'not like': 'Angry',\n",
        "        'not hate': 'Happy', 'not hating': 'Happy', 'not adore': 'Sad', 'not adoring': 'Sad',\n",
        "        'not prefer': 'Sad', 'not preferring': 'Sad', 'not care': 'Angry', 'not mind': 'Angry',\n",
        "        'not minding': 'Sad', 'not want': 'Angry', 'not wanting': 'Sad', 'not need': 'Angry',\n",
        "        'not needing': 'Angry', 'not desire': 'Sad', 'not desiring': 'Sad', 'not wish': 'Sad',\n",
        "        'not wishing': 'Sad', 'not hope': 'Sad', 'not hoping': 'Sad', 'not appreciate': 'Sad',\n",
        "        'not appreciating': 'Sad', 'not value': 'Sad', 'not valuing': 'Sad', 'not owe': 'Sad',\n",
        "        'not owing': 'Sad', 'not seem': 'Sad', 'not seeming': 'Sad', 'not fit': 'Sad', 'not fitting': 'Sad',\n",
        "        'not depend': 'Sad', 'not depending': 'Sad', 'not matter': 'Sad', 'not afford': 'Sad',\n",
        "        'not affording': 'Sad', 'not aim': 'Sad', 'not aiming': 'Sad', 'not attempt': 'Angry',\n",
        "        'not attempting': 'Angry', 'not ask': 'Angry', 'not asking': 'Angry', 'not arrange': 'Angry',\n",
        "        'not arranging': 'Angry', 'not beg': 'Angry', 'not begging': 'Angry', 'not begin': 'Angry',\n",
        "        'not beginning': 'Angry', 'not caring': 'Angry', 'not choose': 'Angry', 'not choosing': 'Angry',\n",
        "        'not claim': 'Angry', 'not claiming': 'Angry', 'not consent': 'Angry', 'not consenting': 'Angry',\n",
        "        'not continue': 'Angry', 'not continuing': 'Angry', 'not dare': 'Angry', 'not daring': 'Angry',\n",
        "        'not decide': 'Sad', 'not deciding': 'Sad', 'not demand': 'Angry', 'not demanding': 'Angry',\n",
        "        'not deserve': 'Angry', 'not deserving': 'Angry', 'not expect': 'Angry', 'not expecting': 'Angry',\n",
        "        'not fail': 'Happy', 'not failing': 'Happy', 'not get': 'Sad', 'not getting': 'Sad',\n",
        "        'not hesitate': 'Sad', 'not hesitating': 'Sad', 'not hurry': 'Happy', 'not hurrying': 'Happy',\n",
        "        'not intend': 'Sad', 'not intending': 'Sad', 'not learn': 'Angry', 'not learning': 'Angry',\n",
        "        'not liking': 'Angry', 'not loving': 'Sad', 'not manage': 'Angry', 'not managing': 'Angry',\n",
        "        'not neglect': 'Sad', 'not neglecting': 'Sad', 'not offer': 'Angry', 'not offering': 'Angry',\n",
        "        'not plan': 'Angry', 'not planing': 'Angry', 'not prepare': 'Angry', 'not preparing': 'Angry',\n",
        "        'not pretend': 'Angry', 'not pretending': 'Angry', 'not proceed': 'Angry', 'not proceeding': 'Angry',\n",
        "        'not propose': 'Angry', 'not proposing': 'Sad', 'not refuse': 'Sad', 'not refusing': 'Sad',\n",
        "        'not start': 'Sad', 'not starting': 'Sad', 'not stop': 'Happy', 'not stopping': 'Happy',\n",
        "        'not struggle': 'Angry', 'not struggling': 'Angry', 'not swear': 'Angry', 'not swearing': 'Angry',\n",
        "        'not threaten': 'Happy', 'not threatening': 'Happy', 'not try': 'Angry', 'not trying': 'Angry',\n",
        "        'not volunteer': 'Angry', 'not volunteering': 'Angry', 'not wait': 'Angry', 'not waiting': 'Angry',\n",
        "        'not feel': 'Sad', 'not feeling': 'Sad', \"not able\": \"Sad\", \"not do\": \"Sad\",\n",
        "        'not apologize': 'Sad', 'not apologizing': 'Sad', 'not forgive': 'Angry', 'not forgiving': 'Angry',\n",
        "        'not trust': 'Angry', 'not trusting': 'Angry', 'not regret': 'Angry', 'not regretting': 'Angry',\n",
        "        'not rejoice': 'Sad', 'not rejoicing': 'Sad', 'not admire': 'Sad', 'not admiring': 'Sad',\n",
        "        'not compliment': 'Sad', 'not complimenting': 'Sad', 'not criticize': 'Happy', 'not criticizing': 'Happy',\n",
        "        'not encourage': 'Angry', 'not encouraging': 'Angry', 'not insult': 'Sad', 'not insulting': 'Sad',\n",
        "        'not praise': 'Angry', 'not praising': 'Angry', 'not support': 'Angry', 'not supporting': 'Angry',\n",
        "        'not blame': 'Sad', 'not blaming': 'Sad', 'not defend': 'Sad', 'not defending': 'Sad',\n",
        "        'not appreciate': 'Sad', 'not appreciating': 'Sad', 'not enjoy': 'Sad', 'not enjoying': 'Sad',\n",
        "        'not like': 'Angry', 'not liking': 'Angry', 'not love': 'Sad', 'not loving': 'Sad',\n",
        "        'not prefer': 'Sad', 'not preferring': 'Sad', 'not want': 'Angry', 'not wanting': 'Sad',\n",
        "        'not believe': 'Angry', 'not believing': 'Angry', 'not doubt': 'Happy', 'not doubting': 'Happy',\n",
        "        'not imagine': 'Sad', 'not imagining': 'Sad', 'not realize': 'Sad', 'not realizing': 'Sad',\n",
        "        'not remember': 'Sad', 'not remembering': 'Sad', 'not recognize': 'Sad', 'not recognizing': 'Sad',\n",
        "        'not consider': 'Sad', 'not considering': 'Sad', 'not think': 'Sad', 'not thinking': 'Sad',\n",
        "        'not forget': 'Angry', 'not forgetting': 'Angry', 'not ignore': 'Angry', 'not ignoring': 'Angry',\n",
        "        'not overlook': 'Angry', 'not overlooking': 'Angry', 'not understand': 'Sad', 'not understanding': 'Sad',\n",
        "        'not hear': 'Angry', 'not hearing': 'Angry', 'not listen': 'Angry', 'not listening': 'Angry',\n",
        "        'not look': 'Angry', 'not looking': 'Angry', 'not smell': 'Angry', 'not smelling': 'Angry',\n",
        "        'not taste': 'Angry', 'not tasting': 'Angry', 'not touch': 'Angry', 'not touching': 'Angry',\n",
        "        'not feel': 'Sad', 'not feeling': 'Sad', 'not sense': 'Sad', 'not sensing': 'Sad',\n",
        "        'not suppose': 'Angry', 'not supposing': 'Angry', 'not expect': 'Angry', 'not expecting': 'Angry',\n",
        "        'not wait': 'Angry', 'not waiting': 'Angry', 'not long': 'Angry', 'not longing': 'Angry',\n",
        "        'not yearn': 'Angry', 'not yearning': 'Angry', 'not wish': 'Sad', 'not wishing': 'Sad',\n",
        "        'not hope': 'Sad', 'not hoping': 'Sad', 'not desire': 'Sad', 'not desiring': 'Sad',\n",
        "        'not miss': 'Angry', 'not missing': 'Angry', 'not need': 'Angry', 'not needing': 'Angry',\n",
        "        'not want': 'Angry', 'not wanting': 'Sad', 'not require': 'Angry', 'not requiring': 'Angry',\n",
        "        'not demand': 'Angry', 'not demanding': 'Angry', 'not insist': 'Angry', 'not insisting': 'Angry',\n",
        "        'not force': 'Angry', 'not forcing': 'Angry', 'not push': 'Angry', 'not pushing': 'Angry',\n",
        "        'not pull': 'Angry', 'not pulling': 'Angry', 'not drag': 'Angry', 'not dragging': 'Angry',\n",
        "        'not carry': 'Angry', 'not carrying': 'Angry', 'not lift': 'Angry', 'not lifting': 'Angry',\n",
        "        'not drop': 'Angry', 'not dropping': 'Angry', 'not throw': 'Angry', 'not throwing': 'Angry',\n",
        "        'not catch': 'Angry', 'not catching': 'Angry', 'not capture': 'Angry', 'not capturing': 'Angry',\n",
        "        'not grab': 'Angry', 'not grabbing': 'Angry', 'not touch': 'Angry', 'not touching': 'Angry',\n",
        "        'not reach': 'Angry', 'not reaching': 'Angry', 'not approach': 'Angry', 'not approaching': 'Angry',\n",
        "        'not avoid': 'Angry', 'not avoiding': 'Angry', 'not evade': 'Angry', 'not evading': 'Angry',\n",
        "        'not elude': 'Angry', 'not eluding': 'Angry', 'not escape': 'Angry', 'not escaping': 'Angry',\n",
        "        'not run': 'Angry', 'not running': 'Angry', 'not jog': 'Angry', 'not jogging': 'Angry',\n",
        "        'not walk': 'Angry', 'not walking': 'Angry', 'not crawl': 'Angry', 'not crawling': 'Angry',\n",
        "        'not sneak': 'Angry', 'not sneaking': 'Angry', 'not tiptoe': 'Angry', 'not tiptoeing': 'Angry',\n",
        "        'not dance': 'Angry', 'not dancing': 'Angry', 'not stomp': 'Angry', 'not stomping': 'Angry',\n",
        "        'not shake': 'Angry', 'not shaking': 'Angry', 'not tremble': 'Angry', 'not trembling': 'Angry',\n",
        "        'not shiver': 'Angry', 'not shivering': 'Angry', 'not quiver': 'Angry', 'not quivering': 'Angry',\n",
        "        'not vibrate': 'Angry', 'not vibrating': 'Angry', 'not pulsate': 'Angry', 'not pulsating': 'Angry',\n",
        "        'not throb': 'Angry', 'not throbbing': 'Angry', 'not beat': 'Angry', 'not beating': 'Angry',\n",
        "        'not palpitate': 'Angry', 'not palpitating': 'Angry', 'not pump': 'Angry', 'not pumping': 'Angry',\n",
        "        'not glide': 'Angry', 'not gliding': 'Angry', 'not slide': 'Angry', 'not sliding': 'Angry',\n",
        "        'not slip': 'Angry', 'not slipping': 'Angry', 'not skid': 'Angry'\n",
        "}\n",
        "\n",
        "shortcuts = {\n",
        "    'u': 'you', 'y': 'why', 'r': 'are', 'doin': 'doing', 'hw': 'how', 'k': 'okay', 'm': 'am',\n",
        "    'b4': 'before',\n",
        "                   'idc': \"i do not care\", 'ty': 'thank you', 'wlcm': 'welcome', 'bc': 'because', '<3': 'love',\n",
        "                   'xoxo': 'love',\n",
        "                   'ttyl': 'talk to you later', 'gr8': 'great', 'bday': 'birthday', 'awsm': 'awesome', 'gud': 'good',\n",
        "                   'h8': 'hate',\n",
        "                   'lv': 'love', 'dm': 'direct message', 'rt': 'retweet', 'wtf': 'hate', 'idgaf': 'hate',\n",
        "                   'irl': 'in real life', 'yolo': 'you only live once', \"don't\": \"do not\", 'g8': 'great',\n",
        "                   \"won't\": \"will not\", 'tbh': 'to be honest', 'caj': 'casual', 'Ikr': 'I know, right?',\n",
        "                   'omw': 'on my way',\n",
        "                   'ofc': 'of course', 'Idc': \"I don't care\", 'Irl': 'In real life', 'tbf': 'To be fair',\n",
        "                   'obvs': 'obviously', 'v': 'very', 'atm': 'at the moment',\n",
        "                   'col': 'crying out loud', 'gbu': 'god bless you', 'gby': 'god bless you', 'gotcha': 'I got you',\n",
        "                   'hehe': 'laughing', 'haha': 'laughing', 'hf': 'have fun',\n",
        "                   'hry': 'hurry', 'hw': 'hardwork', 'idc': 'i don’t care', 'ikr': 'i know right', 'k': 'ok',\n",
        "                   'lmao': 'laughing my ass off', 'lol': 'laughing out loud',\n",
        "                   'n1': 'nice one', 'na': 'not available', 'qt': 'cutie', 'qtpi': 'cutie pie',\n",
        "                   'rip': 'rest in peace',\n",
        "                   'sry': 'sorry', 'tc': 'take care',\n",
        "                   'thnks': 'thanks', 'thx': 'thanks', 'thnk': 'thanks', 'ttyl': 'talk to you later', 'txt': 'text',\n",
        "                   'ugh': 'disgusted', 'w8': 'wait', \"not sad\": \"happy\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTfaCIzdCLPA"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VpImxOjQMxJG"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/final_dataset.csv\", header = None)\n",
        "X = dataset[0].values\n",
        "y = dataset[1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGeMIe5zJaKJ",
        "outputId": "210e6841-98ed-4d68-912e-3079b762feed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19999\n",
            "['anger' 'fear' 'joy' 'love' 'sadness' 'surprise']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "emotions = le.inverse_transform([0,1,2,3,4,5])\n",
        "print(len(y))\n",
        "print(emotions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qekztq71CixT"
      },
      "source": [
        "### Cleaning Texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jjtkHUzt7k7F"
      },
      "outputs": [],
      "source": [
        "def remove_contradictions(text):\n",
        "    if \"n't\" in text:\n",
        "        text = text.replace(\"n't\", \" not\")\n",
        "    for pattern, replacement in contractions.items():\n",
        "        text = re.sub(pattern, replacement, text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "67PUcLrq8OOC"
      },
      "outputs": [],
      "source": [
        "def removing_not(text):\n",
        "        f = re.findall(\"not\\s\\w+\", text)\n",
        "        for i in f:\n",
        "            try:\n",
        "                text = text.replace(i, nots[i])\n",
        "            except:\n",
        "                pass\n",
        "        text = text.lower()\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xoA-h2Kr8u_4"
      },
      "outputs": [],
      "source": [
        "def removing_shortcuts(text):\n",
        "    full_words = []\n",
        "\n",
        "    for token in text:\n",
        "        if token in shortcuts.keys():\n",
        "            token = shortcuts[token]\n",
        "        full_words.append(token)\n",
        "    text = \" \".join(full_words)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PtNNWZCk_AZ3"
      },
      "outputs": [],
      "source": [
        "def removing_stopwords(text):\n",
        "    return [word for word in text if not word in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QDs887QKNctr"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for i in X:\n",
        "  review = re.sub(\"[^a-zA-Z]\",\" \",i)\n",
        "  review = review.lower()\n",
        "  review = re.sub(r'http\\S+|www.\\S+', '', review)\n",
        "  review = remove_contradictions(review)\n",
        "  review = removing_not(review)\n",
        "  review = review.split()\n",
        "  review = removing_shortcuts(review)\n",
        "  review = ' '.join([i for i in review.split() if not i.isdigit()])\n",
        "  review = word_tokenize(review)\n",
        "  review = removing_stopwords(review)\n",
        "  lemma = WordNetLemmatizer()\n",
        "  review = [lemma.lemmatize(word) for word in review]\n",
        "  review = \" \".join(review)\n",
        "  corpus.append(review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLqmAkANCp1-"
      },
      "source": [
        "### Creating the Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEUeuJkEfpXT",
        "outputId": "8f359adc-f8c4-465a-c0ef-1e0b386a24b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19999 2000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=2000)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "print(len(X),len(X[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH_VjgPzC2cd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HiFLzVA0t8Fd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Jv-jxOkW8dh"
      },
      "source": [
        "## Classification Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKwiZfGgPfVG"
      },
      "source": [
        "### MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DmP8hCRPefN",
        "outputId": "0677ef2e-52c9-4f28-9567-95600a631b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 83.8000%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.83      0.83      0.83       538\n",
            "        fear       0.77      0.77      0.77       505\n",
            "         joy       0.86      0.88      0.87      1294\n",
            "        love       0.72      0.69      0.71       342\n",
            "     sadness       0.90      0.89      0.90      1174\n",
            "    surprise       0.69      0.67      0.68       147\n",
            "\n",
            "    accuracy                           0.84      4000\n",
            "   macro avg       0.80      0.79      0.79      4000\n",
            "weighted avg       0.84      0.84      0.84      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "MLP_classifier = MLPClassifier(max_iter = 1000)\n",
        "MLP_classifier.fit(X_train, y_train)\n",
        "y_pred = MLP_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luKHj-NxP1y-"
      },
      "source": [
        "### GB Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uMhKOC5mPvx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e78205-ab01-409c-dd1b-59e487415aa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 83.6250%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.94      0.75      0.83       538\n",
            "        fear       0.90      0.72      0.80       505\n",
            "         joy       0.74      0.96      0.83      1294\n",
            "        love       0.86      0.73      0.79       342\n",
            "     sadness       0.94      0.84      0.88      1174\n",
            "    surprise       0.71      0.74      0.73       147\n",
            "\n",
            "    accuracy                           0.84      4000\n",
            "   macro avg       0.85      0.79      0.81      4000\n",
            "weighted avg       0.85      0.84      0.84      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GB_classifier = GradientBoostingClassifier()\n",
        "GB_classifier.fit(X_train, y_train)\n",
        "y_pred = GB_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Ia3WU9yCHS"
      },
      "source": [
        "### LightGBM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OyA0qdz_yKZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc24bd32-b7e3-4a22-9197-5374bd54ee26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.199085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3207\n",
            "[LightGBM] [Info] Number of data points in the train set: 15999, number of used features: 1199\n",
            "[LightGBM] [Info] Start training from score -1.997338\n",
            "[LightGBM] [Info] Start training from score -2.147658\n",
            "[LightGBM] [Info] Start training from score -1.073979\n",
            "[LightGBM] [Info] Start training from score -2.510931\n",
            "[LightGBM] [Info] Start training from score -1.241482\n",
            "[LightGBM] [Info] Start training from score -3.331143\n",
            "Accuracy = 87.1500%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.87      0.86      0.86       538\n",
            "        fear       0.84      0.80      0.82       505\n",
            "         joy       0.86      0.91      0.89      1294\n",
            "        love       0.76      0.80      0.78       342\n",
            "     sadness       0.95      0.91      0.93      1174\n",
            "    surprise       0.73      0.73      0.73       147\n",
            "\n",
            "    accuracy                           0.87      4000\n",
            "   macro avg       0.84      0.83      0.83      4000\n",
            "weighted avg       0.87      0.87      0.87      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "LGBM_classifier = LGBMClassifier()\n",
        "LGBM_classifier.fit(X_train, y_train)\n",
        "y_pred = LGBM_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw1PvphwsBZy"
      },
      "source": [
        "### CatBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Fj3N72ZqsP0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74e1ffa-7154-4efe-b094-94ab148be195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 88.9500%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.91      0.88      0.89       538\n",
            "        fear       0.85      0.82      0.84       505\n",
            "         joy       0.87      0.95      0.91      1294\n",
            "        love       0.89      0.72      0.80       342\n",
            "     sadness       0.93      0.93      0.93      1174\n",
            "    surprise       0.78      0.69      0.73       147\n",
            "\n",
            "    accuracy                           0.89      4000\n",
            "   macro avg       0.87      0.83      0.85      4000\n",
            "weighted avg       0.89      0.89      0.89      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "CB_classifier = CatBoostClassifier(logging_level='Silent')\n",
        "CB_classifier.fit(X_train, y_train)\n",
        "y_pred = CB_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umluhHe8riQ0"
      },
      "source": [
        "### XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1vpbR4syrsoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43ebf77f-da67-418e-f62e-47905f75d4f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 88.7250%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.90      0.88      0.89       538\n",
            "        fear       0.86      0.84      0.85       505\n",
            "         joy       0.88      0.91      0.90      1294\n",
            "        love       0.79      0.82      0.81       342\n",
            "     sadness       0.95      0.91      0.93      1174\n",
            "    surprise       0.75      0.78      0.77       147\n",
            "\n",
            "    accuracy                           0.89      4000\n",
            "   macro avg       0.86      0.86      0.86      4000\n",
            "weighted avg       0.89      0.89      0.89      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "XGBC_classifier = XGBClassifier()\n",
        "XGBC_classifier.fit(X_train, y_train)\n",
        "y_pred = XGBC_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9CGgYznQCpN"
      },
      "source": [
        "### Extra Trees Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SR-JmuzHP91R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d9e34a7-c899-4df7-eb13-b047e0e0ed1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 88.3500%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.89      0.89      0.89       538\n",
            "        fear       0.83      0.83      0.83       505\n",
            "         joy       0.92      0.89      0.91      1294\n",
            "        love       0.80      0.81      0.80       342\n",
            "     sadness       0.92      0.93      0.92      1174\n",
            "    surprise       0.66      0.75      0.70       147\n",
            "\n",
            "    accuracy                           0.88      4000\n",
            "   macro avg       0.84      0.85      0.84      4000\n",
            "weighted avg       0.89      0.88      0.88      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "ET_classifier = ExtraTreesClassifier()\n",
        "ET_classifier.fit(X_train, y_train)\n",
        "y_pred = ET_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhePsbgOPc7_"
      },
      "source": [
        "### Random Forest Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qmku0om9Pfy3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b7fbea-f392-4d64-bb8f-f5eb33a64bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 87.4250%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.88      0.89      0.88       538\n",
            "        fear       0.82      0.82      0.82       505\n",
            "         joy       0.92      0.87      0.89      1294\n",
            "        love       0.78      0.80      0.79       342\n",
            "     sadness       0.91      0.93      0.92      1174\n",
            "    surprise       0.65      0.74      0.69       147\n",
            "\n",
            "    accuracy                           0.87      4000\n",
            "   macro avg       0.83      0.84      0.83      4000\n",
            "weighted avg       0.88      0.87      0.87      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest_classifier = RandomForestClassifier()\n",
        "random_forest_classifier.fit(X_train, y_train)\n",
        "y_pred = random_forest_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywlNibWMPYcf"
      },
      "source": [
        "### Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GUcAwOfaPblX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6048842a-0a29-4564-ec1b-e7f009e0bd17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 83.5000%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.78      0.86      0.82       538\n",
            "        fear       0.78      0.81      0.80       505\n",
            "         joy       0.89      0.79      0.84      1294\n",
            "        love       0.74      0.78      0.76       342\n",
            "     sadness       0.89      0.91      0.90      1174\n",
            "    surprise       0.64      0.78      0.70       147\n",
            "\n",
            "    accuracy                           0.83      4000\n",
            "   macro avg       0.79      0.82      0.80      4000\n",
            "weighted avg       0.84      0.83      0.84      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_classifier = DecisionTreeClassifier()\n",
        "decision_classifier.fit(X_train, y_train)\n",
        "y_pred = decision_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1y31i1uPRHO"
      },
      "source": [
        "### Logistic Regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hImOl32HPVpW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d45acc96-04cc-43b2-a71b-627a10761c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 88.5250%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.89      0.87      0.88       538\n",
            "        fear       0.85      0.81      0.83       505\n",
            "         joy       0.90      0.92      0.91      1294\n",
            "        love       0.81      0.78      0.80       342\n",
            "     sadness       0.92      0.93      0.93      1174\n",
            "    surprise       0.71      0.73      0.72       147\n",
            "\n",
            "    accuracy                           0.89      4000\n",
            "   macro avg       0.85      0.84      0.84      4000\n",
            "weighted avg       0.88      0.89      0.88      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_classifier = LogisticRegression(max_iter = 1000)\n",
        "logistic_classifier.fit(X_train, y_train)\n",
        "y_pred = logistic_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wZiSMbCPxqZ"
      },
      "source": [
        "### Kernal SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ck60nqZfP0iJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ec0e82-f83c-4b3f-ee27-d152c2f820b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 83.8250%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.89      0.76      0.82       538\n",
            "        fear       0.83      0.73      0.78       505\n",
            "         joy       0.79      0.94      0.86      1294\n",
            "        love       0.88      0.58      0.70       342\n",
            "     sadness       0.87      0.92      0.90      1174\n",
            "    surprise       0.87      0.50      0.63       147\n",
            "\n",
            "    accuracy                           0.84      4000\n",
            "   macro avg       0.86      0.74      0.78      4000\n",
            "weighted avg       0.84      0.84      0.83      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "kernal_classifier = SVC(kernel = 'rbf')\n",
        "kernal_classifier.fit(X_train, y_train)\n",
        "y_pred = kernal_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S9YgOoGPqwB"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "b4Fkb_AZPsCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650ce2c9-fe22-4e84-ff0d-9e65a0656b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 87.0000%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.86      0.86      0.86       538\n",
            "        fear       0.84      0.83      0.83       505\n",
            "         joy       0.88      0.90      0.89      1294\n",
            "        love       0.77      0.79      0.78       342\n",
            "     sadness       0.92      0.91      0.92      1174\n",
            "    surprise       0.71      0.71      0.71       147\n",
            "\n",
            "    accuracy                           0.87      4000\n",
            "   macro avg       0.83      0.83      0.83      4000\n",
            "weighted avg       0.87      0.87      0.87      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_classifier = SVC(kernel = 'linear')\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzLv2ypNPjKI"
      },
      "source": [
        "### K-Nearest Neighbors (K-NN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "knZpS609PnmA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f9aa8a0-3b9f-4cad-d119-92199717f5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 56.2500%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.36      0.61      0.45       538\n",
            "        fear       0.52      0.48      0.49       505\n",
            "         joy       0.62      0.65      0.63      1294\n",
            "        love       0.61      0.24      0.34       342\n",
            "     sadness       0.69      0.62      0.65      1174\n",
            "    surprise       0.52      0.25      0.34       147\n",
            "\n",
            "    accuracy                           0.56      4000\n",
            "   macro avg       0.55      0.47      0.49      4000\n",
            "weighted avg       0.59      0.56      0.56      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "K_nearest_classifier = KNeighborsClassifier()\n",
        "K_nearest_classifier.fit(X_train, y_train)\n",
        "y_pred = K_nearest_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xif2Y8aIPJen"
      },
      "source": [
        "### Naive Bayes model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "txEmfSZiPO6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24349c30-a848-47f8-cd86-7271ac1c8443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 39.7000%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.38      0.46      0.42       538\n",
            "        fear       0.35      0.58      0.44       505\n",
            "         joy       0.84      0.33      0.47      1294\n",
            "        love       0.24      0.71      0.35       342\n",
            "     sadness       0.78      0.26      0.39      1174\n",
            "    surprise       0.13      0.52      0.20       147\n",
            "\n",
            "    accuracy                           0.40      4000\n",
            "   macro avg       0.45      0.48      0.38      4000\n",
            "weighted avg       0.62      0.40      0.42      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "naive_classifier = GaussianNB()\n",
        "naive_classifier.fit(X_train,y_train)\n",
        "y_pred = naive_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEra42zRmJUh"
      },
      "source": [
        "## Voting Classifier Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdHhq03TmO4R",
        "outputId": "2db8b563-c3ec-43dc-b796-7dcb46ab92c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.199581 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3165\n",
            "[LightGBM] [Info] Number of data points in the train set: 15999, number of used features: 1183\n",
            "[LightGBM] [Info] Start training from score -1.997799\n",
            "[LightGBM] [Info] Start training from score -2.126995\n",
            "[LightGBM] [Info] Start training from score -1.090024\n",
            "[LightGBM] [Info] Start training from score -2.480603\n",
            "[LightGBM] [Info] Start training from score -1.236950\n",
            "[LightGBM] [Info] Start training from score -3.352345\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;MLPC&#x27;, MLPClassifier(max_iter=1000)),\n",
              "                             (&#x27;GBC&#x27;, GradientBoostingClassifier()),\n",
              "                             (&#x27;LGBMC&#x27;, LGBMClassifier()),\n",
              "                             (&#x27;XGBC&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            featu...\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=None, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=None, ...)),\n",
              "                             (&#x27;ETC&#x27;, ExtraTreesClassifier()),\n",
              "                             (&#x27;RFC&#x27;, RandomForestClassifier()),\n",
              "                             (&#x27;DTC&#x27;, DecisionTreeClassifier()),\n",
              "                             (&#x27;LC&#x27;, LogisticRegression(max_iter=1000)),\n",
              "                             (&#x27;KSVMC&#x27;, SVC()), (&#x27;SVMC&#x27;, SVC(kernel=&#x27;linear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;MLPC&#x27;, MLPClassifier(max_iter=1000)),\n",
              "                             (&#x27;GBC&#x27;, GradientBoostingClassifier()),\n",
              "                             (&#x27;LGBMC&#x27;, LGBMClassifier()),\n",
              "                             (&#x27;XGBC&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            featu...\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=None, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=None, ...)),\n",
              "                             (&#x27;ETC&#x27;, ExtraTreesClassifier()),\n",
              "                             (&#x27;RFC&#x27;, RandomForestClassifier()),\n",
              "                             (&#x27;DTC&#x27;, DecisionTreeClassifier()),\n",
              "                             (&#x27;LC&#x27;, LogisticRegression(max_iter=1000)),\n",
              "                             (&#x27;KSVMC&#x27;, SVC()), (&#x27;SVMC&#x27;, SVC(kernel=&#x27;linear&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>MLPC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GBC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LGBMC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>XGBC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ETC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>RFC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>DTC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>KSVMC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVMC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "VotingClassifier(estimators=[('MLPC', MLPClassifier(max_iter=1000)),\n",
              "                             ('GBC', GradientBoostingClassifier()),\n",
              "                             ('LGBMC', LGBMClassifier()),\n",
              "                             ('XGBC',\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            featu...\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=None, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=None, ...)),\n",
              "                             ('ETC', ExtraTreesClassifier()),\n",
              "                             ('RFC', RandomForestClassifier()),\n",
              "                             ('DTC', DecisionTreeClassifier()),\n",
              "                             ('LC', LogisticRegression(max_iter=1000)),\n",
              "                             ('KSVMC', SVC()), ('SVMC', SVC(kernel='linear'))])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "MLP_classifier = MLPClassifier(max_iter = 1000)\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GB_classifier = GradientBoostingClassifier()\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "LGBM_classifier = LGBMClassifier()\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "XGBC_classifier = XGBClassifier()\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "ET_classifier = ExtraTreesClassifier()\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest_classifier = RandomForestClassifier()\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_classifier = DecisionTreeClassifier()\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_classifier = LogisticRegression(max_iter = 1000)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "kernal_classifier = SVC(kernel = 'rbf')\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "svm_classifier = SVC(kernel = 'linear')\n",
        "\n",
        "\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('MLPC', MLP_classifier),\n",
        "        ('GBC', GB_classifier),\n",
        "        ('LGBMC', LGBM_classifier),\n",
        "        ('XGBC', XGBC_classifier),\n",
        "        ('ETC', ET_classifier),\n",
        "        ('RFC', random_forest_classifier),\n",
        "        ('DTC', decision_classifier),\n",
        "        ('LC', logistic_classifier),\n",
        "        ('KSVMC', kernal_classifier),\n",
        "        ('SVMC', svm_classifier)\n",
        "        ],\n",
        "    voting='hard')\n",
        "ensemble.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEoN1pM-mUmK",
        "outputId": "37ea8e57-abea-463f-b4fb-d9702f96fa09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 90.4250%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.89      0.90      0.89       539\n",
            "        fear       0.87      0.86      0.87       466\n",
            "         joy       0.92      0.93      0.92      1381\n",
            "        love       0.82      0.83      0.83       302\n",
            "     sadness       0.95      0.92      0.93      1153\n",
            "    surprise       0.80      0.85      0.82       159\n",
            "\n",
            "    accuracy                           0.90      4000\n",
            "   macro avg       0.87      0.88      0.88      4000\n",
            "weighted avg       0.90      0.90      0.90      4000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = ensemble.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rieLW7GNKei2"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV8L3a7eSyZJ",
        "outputId": "743f4c81-cb11-4c67-f6ae-2c740d50273f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural Network : 0.85575\n",
            "GradientBoostingClassifier:  0.85175\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121051 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3165\n",
            "[LightGBM] [Info] Number of data points in the train set: 15999, number of used features: 1183\n",
            "[LightGBM] [Info] Start training from score -1.997799\n",
            "[LightGBM] [Info] Start training from score -2.126995\n",
            "[LightGBM] [Info] Start training from score -1.090024\n",
            "[LightGBM] [Info] Start training from score -2.480603\n",
            "[LightGBM] [Info] Start training from score -1.236950\n",
            "[LightGBM] [Info] Start training from score -3.352345\n",
            "LGBM_classifier:  0.889\n",
            "CatBoost : 0.90375\n",
            "XGB : 0.89975\n",
            "ExtraTreesClassifier : 0.89475\n",
            "RandomForest : 0.88625\n",
            "DecisionTree : 0.8355\n",
            "LogisticRegression : 0.8925\n",
            "Kernel SVM : 0.85525\n",
            "Linear SVM : 0.877\n",
            "SVM : 0.85525\n",
            "KNeighbours : 0.568\n",
            "Naive Bayes : 0.406\n",
            "AdaBoostClassifier : 0.361\n"
          ]
        }
      ],
      "source": [
        "classifiers = [['Neural Network :', MLPClassifier(max_iter = 1000)],\n",
        "               ['GradientBoostingClassifier: ', GradientBoostingClassifier()],\n",
        "               ['LGBM_classifier: ', LGBMClassifier()],\n",
        "               ['CatBoost :', CatBoostClassifier(logging_level='Silent')],\n",
        "               ['XGB :', XGBClassifier()],\n",
        "               ['ExtraTreesClassifier :', ExtraTreesClassifier()],\n",
        "               ['RandomForest :',RandomForestClassifier()],\n",
        "               ['DecisionTree :',DecisionTreeClassifier()],\n",
        "               ['LogisticRegression :', LogisticRegression(max_iter = 1000)],\n",
        "               ['Kernel SVM :', SVC(kernel = 'rbf')],\n",
        "               ['Linear SVM :', SVC(kernel = \"linear\")],\n",
        "               ['SVM :', SVC()],\n",
        "               ['KNeighbours :', KNeighborsClassifier()],\n",
        "               ['Naive Bayes :', GaussianNB()],\n",
        "               ['AdaBoostClassifier :', AdaBoostClassifier()],\n",
        "               ]\n",
        "\n",
        "for name,classifier in classifiers:\n",
        "    classifier = classifier\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(name, accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JilrBBRzsbyA"
      },
      "source": [
        "## Predict Single Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "39hpX8mboYBc"
      },
      "outputs": [],
      "source": [
        "def predict_emotion(text, classifier):\n",
        "  text = text.replace(\"\\n\",\" \")\n",
        "  review = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
        "  review = review.lower()\n",
        "  review = re.sub(r'http\\S+|www.\\S+', '', review)\n",
        "  review = remove_contradictions(review)\n",
        "  review = removing_not(review)\n",
        "  review = review.split()\n",
        "  review = removing_shortcuts(review)\n",
        "  review = ' '.join([i for i in review.split() if not i.isdigit()])\n",
        "  review = word_tokenize(review)\n",
        "  review = removing_stopwords(review)\n",
        "  lemma = WordNetLemmatizer()\n",
        "  review = [lemma.lemmatize(word) for word in review]\n",
        "  review = \" \".join(review)\n",
        "  test = cv.transform([review]).toarray()\n",
        "  result = classifier.predict(test)\n",
        "  result = le.inverse_transform(result)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBU25PLVsqnb",
        "outputId": "998e0d88-47a7-40af-af80-5a0eec6cfe04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['joy']\n",
            "['joy']\n",
            "['joy']\n",
            "['joy']\n",
            "['joy']\n",
            "['joy']\n",
            "['anger']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:155: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['anger']\n",
            "['joy']\n",
            "['joy']\n",
            "['sadness']\n",
            "['fear']\n"
          ]
        }
      ],
      "source": [
        "text = '''Namaskar, I am Yash Vaidya. Welcome to Lok Satta's Podcast.\n",
        "Friends, many things that happen around us are precious to us.\n",
        "That's why Lok Satta has brought to you the Kutuhal Podcast.\n",
        "Today's podcast is about plastic in the body of marine life.\n",
        "In 1965, a plastic bag was found on a device used by fishermen in the Irish Sea.\n",
        "The world's largest marine organization has declared that this is the first case of plastic waste in the sea water.\n",
        "Since then, plastic waste has been going into the sea for decades.\n",
        "According to surveys carried out by various institutions on the international level,\n",
        "there is a total of 20 crore metric tons of plastic waste in the sea today.\n",
        "Every year, there is a total of 381 lakh tons of plastic waste in the sea.\n",
        "A large part of the sea shore is made up of broken and unusable nets of fish.\n",
        "Plastic nets, small and large fish,\n",
        "the bodies of many species of marine animals,\n",
        "the face of which gets clogged, clogged, and becomes a physical torture.\n",
        "A survey has shown that 10 lakh sea birds and 1 lakh marine animals die of plastic waste every year.\n",
        "Plastic is stuck in fish of the same species on all three sides.\n",
        "Due to the collision of the waves and sunlight in the sea,\n",
        "slowly plastic bottles or bags become small pieces and eventually turn into very fine particles.\n",
        "In recent times, the particles of very fine plastic in the sea\n",
        "have entered the human body through the sea and are causing harm to the health.\n",
        "In 2014, PVC and polythene were found in the rocks of the sea in Hawaii.\n",
        "These rocks have been named plastic lomerits.\n",
        "The Coastal Survey of Kolkata has found large amounts of such rocks in the Andaman Sea in May 2022.\n",
        "These rocks have created a threat to the lives of the residents.\n",
        "Research is still underway on this.\n",
        "In the end, it is necessary for all ordinary citizens to come together to fight this infinite monster of plastic.\n",
        "Plastic waste thrown into the sea is thrown out by the sea many times.\n",
        "We have seen this on the shore many times.\n",
        "Now we should respect this sea.\n",
        "So you were listening to Lok Satta's Kutuhal Podcast.\n",
        "To hear such new topics, visit loksatta.com's audio section.\n",
        "And for the notification of new episodes, don't forget to like and follow Lok Satta's Podcast on your favorite audio platform.\n",
        "'''\n",
        "\n",
        "print(predict_emotion(text, ensemble))\n",
        "print(predict_emotion(text, GB_classifier))\n",
        "print(predict_emotion(text, LGBM_classifier))\n",
        "print(predict_emotion(text, CB_classifier))\n",
        "print(predict_emotion(text, XGBC_classifier))\n",
        "print(predict_emotion(text, ET_classifier))\n",
        "print(predict_emotion(text, random_forest_classifier))\n",
        "print(predict_emotion(text, decision_classifier))\n",
        "print(predict_emotion(text, K_nearest_classifier))\n",
        "print(predict_emotion(text, kernal_classifier))\n",
        "print(predict_emotion(text, svm_classifier))\n",
        "print(predict_emotion(text, naive_classifier))\n",
        "print(predict_emotion(text, logistic_classifier))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PaInD7MxYdJ8",
        "X1kiO9kACE6s",
        "8laN2NPRcH6i",
        "wTfaCIzdCLPA",
        "Qekztq71CixT",
        "CLqmAkANCp1-",
        "DH_VjgPzC2cd",
        "uKwiZfGgPfVG",
        "luKHj-NxP1y-",
        "M2Ia3WU9yCHS",
        "Fw1PvphwsBZy",
        "umluhHe8riQ0",
        "_9CGgYznQCpN",
        "PhePsbgOPc7_",
        "ywlNibWMPYcf",
        "o1y31i1uPRHO",
        "3wZiSMbCPxqZ",
        "3S9YgOoGPqwB",
        "dzLv2ypNPjKI",
        "xif2Y8aIPJen"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}