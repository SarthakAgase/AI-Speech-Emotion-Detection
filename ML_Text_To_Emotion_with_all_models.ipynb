{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarthakAgase/AI-Speech-Emotion-Detection/blob/main/ML_Text_To_Emotion_with_all_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwK5-9FIB-lu"
      },
      "source": [
        "# Emotion Detection Models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "PaInD7MxYdJ8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1kiO9kACE6s"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcIBhxAaFnHp",
        "outputId": "05ebefdb-4fb6-47a6-b0b4-032e8df7be4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re, nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.remove(\"no\")\n",
        "stop_words.remove(\"not\")\n",
        "stop_words.remove(\"nor\")\n",
        "stop_words = [x.lower() for x in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdreXsRUJVm7",
        "outputId": "9f79a36a-0531-42fd-bbe3-a0a432a3e2a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm\n",
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8laN2NPRcH6i"
      },
      "source": [
        "### Pre-Defined Dictionary Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH9bzPAabHzz"
      },
      "outputs": [],
      "source": [
        "contractions = {\n",
        "        \"ai\\snot\": \"am not\",\n",
        "        \"wo\\snot\": \"will not\",\n",
        "        \"would\\snot\": \"would not\",\n",
        "        \"should\\snot\": \"should not\",\n",
        "        \"isn\\snot\": \"is not\",\n",
        "        \"aren\\snot\": \"are not\",\n",
        "        \"wasn\\snot\": \"was not\",\n",
        "        \"weren\\snot\": \"were not\",\n",
        "        \"haven\\snot\": \"have not\",\n",
        "        \"hasn\\snot\": \"has not\",\n",
        "        \"hadn\\snot\": \"had not\",\n",
        "        \"don\\snot\": \"do not\",\n",
        "        \"doesn\\snot\": \"does not\",\n",
        "        \"didn\\snot\": \"did not\",\n",
        "        \"can\\snot\": \"can not\",\n",
        "        \"cannot\": \"can not\",\n",
        "        \"couldn\\snot\": \"could not\",\n",
        "        \"shouldn\\snot\": \"should not\",\n",
        "        \"mightn\\snot\": \"might not\",\n",
        "        \"mustn\\snot\": \"must not\",\n",
        "        \"shan\\snot\": \"shall not\",\n",
        "        \"won\\snot\": \"will not\",\n",
        "        \"ain\\snot\": \"am not\",\n",
        "        \"I\\sam\": \"I am\",\n",
        "        \"you\\sare\": \"you are\",\n",
        "        \"he\\sis\": \"he is\",\n",
        "        \"she\\sis\": \"she is\",\n",
        "        \"it\\sis\": \"it is\",\n",
        "        \"we\\sare\": \"we are\",\n",
        "        \"they\\sare\": \"they are\",\n",
        "        \"I\\swould\": \"I would\",\n",
        "        \"you\\swould\": \"you would\",\n",
        "        \"he\\swould\": \"he would\",\n",
        "        \"she\\swould\": \"she would\",\n",
        "        \"it\\swould\": \"it would\",\n",
        "        \"we\\swould\": \"we would\",\n",
        "        \"they\\swould\": \"they would\",\n",
        "        \"I\\scould\": \"I could\",\n",
        "        \"you\\scould\": \"you could\",\n",
        "        \"he\\scould\": \"he could\",\n",
        "        \"she\\scould\": \"she could\",\n",
        "        \"it\\scould\": \"it could\",\n",
        "        \"we\\scould\": \"we could\",\n",
        "        \"they\\scould\": \"they could\",\n",
        "        \"I\\shave\": \"I have\",\n",
        "        \"you\\shave\": \"you have\",\n",
        "        \"he\\shas\": \"he has\",\n",
        "        \"she\\shas\": \"she has\",\n",
        "        \"it\\shas\": \"it has\",\n",
        "        \"we\\shave\": \"we have\",\n",
        "        \"they\\shave\": \"they have\",\n",
        "        \"I\\swill\": \"I will\",\n",
        "        \"you\\swill\": \"you will\",\n",
        "        \"he\\swill\": \"he will\",\n",
        "        \"she\\swill\": \"she will\",\n",
        "        \"it\\swill\": \"it will\",\n",
        "        \"we\\swill\": \"we will\",\n",
        "        \"they\\swill\": \"they will\",\n",
        "        \"I\\smust\": \"I must\",\n",
        "        \"you\\smust\": \"you must\",\n",
        "        \"he\\smust\": \"he must\",\n",
        "        \"she\\smust\": \"she must\",\n",
        "        \"it\\smust\": \"it must\",\n",
        "        \"we\\smust\": \"we must\",\n",
        "        \"they\\smust\": \"they must\",\n",
        "        \"I\\sshall\": \"I shall\",\n",
        "        \"you\\sshall\": \"you shall\",\n",
        "        \"he\\sshall\": \"he shall\",\n",
        "        \"she\\sshall\": \"she shall\",\n",
        "        \"it\\sshall\": \"it shall\",\n",
        "        \"we\\sshall\": \"we shall\",\n",
        "        \"they\\sshall\": \"they shall\",\n",
        "        \"haven\\s't\": \"have not\",\n",
        "        \"hasn\\s't\": \"has not\",\n",
        "        \"hadn\\s't\": \"had not\",\n",
        "        \"don\\s't\": \"do not\",\n",
        "        \"doesn\\s't\": \"does not\",\n",
        "        \"didn\\s't\": \"did not\",\n",
        "        \"can\\s't\": \"can not\",\n",
        "        \"cannot\": \"can not\",\n",
        "        \"couldn\\s't\": \"could not\",\n",
        "        \"shouldn\\s't\": \"should not\",\n",
        "        \"mightn\\s't\": \"might not\",\n",
        "        \"mustn\\s't\": \"must not\",\n",
        "        \"shan\\s't\": \"shall not\",\n",
        "        \"won\\s't\": \"will not\",\n",
        "        \"ain\\s't\": \"am not\",\n",
        "        \"aren\\s't\": \"are not\",\n",
        "        \"wasn\\s't\": \"was not\",\n",
        "        \"weren\\s't\": \"were not\",\n",
        "        \"I\\sdidn't\": \"I did not\",\n",
        "        \"you\\sdidn't\": \"you did not\",\n",
        "        \"he\\sdidn't\": \"he did not\",\n",
        "        \"she\\sdidn't\": \"she did not\",\n",
        "        \"it\\sdidn't\": \"it did not\",\n",
        "        \"we\\sdidn't\": \"we did not\",\n",
        "        \"they\\sdidn't\": \"they did not\",\n",
        "        \"I\\scannot\": \"I can not\",\n",
        "        \"you\\scannot\": \"you can not\",\n",
        "        \"he\\scannot\": \"he can not\",\n",
        "        \"she\\scannot\": \"she can not\",\n",
        "        \"it\\scannot\": \"it can not\",\n",
        "        \"we\\scannot\": \"we can not\",\n",
        "        \"they\\scannot\": \"they can not\",\n",
        "        \"I\\swon't\": \"I will not\",\n",
        "        \"you\\swon't\": \"you will not\",\n",
        "        \"he\\swon't\": \"he will not\",\n",
        "        \"she\\swon't\": \"she will not\",\n",
        "        \"it\\swon't\": \"it will not\",\n",
        "        \"we\\swon't\": \"we will not\",\n",
        "        \"they\\swon't\": \"they will not\",\n",
        "        \"I\\shasn't\": \"I has not\",\n",
        "        \"you\\shasn't\": \"you has not\",\n",
        "        \"he\\shasn't\": \"he has not\",\n",
        "        \"she\\shasn't\": \"she has not\",\n",
        "        \"it\\shasn't\": \"it has not\",\n",
        "        \"we\\shasn't\": \"we has not\",\n",
        "        \"they\\shasn't\": \"they has not\"\n",
        "}\n",
        "\n",
        "nots = {\n",
        "    'not sad': 'Happy', 'not bad': 'Happy', 'not boring': 'Happy', 'not wrong': 'Happy', 'not bored': 'Happy',\n",
        "        'not jealous': 'Happy', 'not happy': 'Sad', 'not well': 'Sad', 'not suitable': 'Angry',\n",
        "        'not right': 'Angry', 'not good': 'Sad', 'not excited': 'Angry', 'not funny ': 'Sad', 'not kind': 'Sad',\n",
        "        'not proud': 'Angry', 'not cool': 'Angry', 'not funny': 'Angry', 'not kind': 'Angry', 'not open': 'Angry',\n",
        "        'not safe': 'Fear', 'not enough': 'Empty', 'not know': 'Sad', 'not knowing': 'Sad', 'not believe': 'Angry',\n",
        "        'not believing': 'Angry', 'not understand': 'Sad', 'not understanding': 'Sad', 'no doubt': 'Happy',\n",
        "        'not think': 'Sad', 'not thinking': 'Sad', 'not recognise': 'Sad', 'not recognising': 'Sad',\n",
        "        'not forget': 'Angry', 'not forgetting': 'Angry', 'not remember': 'Sad', 'not remembering': 'Sad',\n",
        "        'not imagine': 'Sad', 'not imagining': 'Sad', 'not mean': 'Sad', 'not meaning': 'Sad',\n",
        "        'not agree': 'Angry', 'not agreeing': 'Sad', 'not disagree': 'Happy', 'not disagreeing': 'Happy',\n",
        "        'not deny': 'Sad', 'not denying': 'Sad', 'not promise': 'Angry', 'not promising': 'Angry',\n",
        "        'not satisfy': 'Sad', 'not satisfying': 'Sad', 'not realise': 'Sad', 'not realising': 'Sad',\n",
        "        'not appear': 'Angry', 'not appearing': 'Angry', 'not please': 'Sad', 'not pleasing': 'Sad',\n",
        "        'not impress': 'Sad', 'not impressing': 'Sad', 'not surprise': 'Sad', 'not surprising': 'Sad',\n",
        "        'not concern': 'Sad', 'not concerning': 'Sad', 'not have': 'Sad', 'not having': 'Sad',\n",
        "        'not own': 'Sad', 'not owning': 'Sad', 'not possess': 'Sad', 'not possessing': 'Sad',\n",
        "        'not lack': 'Sad', 'not lacking': 'Sad', 'not consist': 'Sad', 'not consisting': 'Sad',\n",
        "        'not involve': 'Sad', 'not involving': 'Sad', 'not include': 'Sad', 'not including': 'Sad',\n",
        "        'not contain': 'Sad', 'not containing': 'Sad', 'not love': 'Sad', 'not like': 'Angry',\n",
        "        'not hate': 'Happy', 'not hating': 'Happy', 'not adore': 'Sad', 'not adoring': 'Sad',\n",
        "        'not prefer': 'Sad', 'not preferring': 'Sad', 'not care': 'Angry', 'not mind': 'Angry',\n",
        "        'not minding': 'Sad', 'not want': 'Angry', 'not wanting': 'Sad', 'not need': 'Angry',\n",
        "        'not needing': 'Angry', 'not desire': 'Sad', 'not desiring': 'Sad', 'not wish': 'Sad',\n",
        "        'not wishing': 'Sad', 'not hope': 'Sad', 'not hoping': 'Sad', 'not appreciate': 'Sad',\n",
        "        'not appreciating': 'Sad', 'not value': 'Sad', 'not valuing': 'Sad', 'not owe': 'Sad',\n",
        "        'not owing': 'Sad', 'not seem': 'Sad', 'not seeming': 'Sad', 'not fit': 'Sad', 'not fitting': 'Sad',\n",
        "        'not depend': 'Sad', 'not depending': 'Sad', 'not matter': 'Sad', 'not afford': 'Sad',\n",
        "        'not affording': 'Sad', 'not aim': 'Sad', 'not aiming': 'Sad', 'not attempt': 'Angry',\n",
        "        'not attempting': 'Angry', 'not ask': 'Angry', 'not asking': 'Angry', 'not arrange': 'Angry',\n",
        "        'not arranging': 'Angry', 'not beg': 'Angry', 'not begging': 'Angry', 'not begin': 'Angry',\n",
        "        'not beginning': 'Angry', 'not caring': 'Angry', 'not choose': 'Angry', 'not choosing': 'Angry',\n",
        "        'not claim': 'Angry', 'not claiming': 'Angry', 'not consent': 'Angry', 'not consenting': 'Angry',\n",
        "        'not continue': 'Angry', 'not continuing': 'Angry', 'not dare': 'Angry', 'not daring': 'Angry',\n",
        "        'not decide': 'Sad', 'not deciding': 'Sad', 'not demand': 'Angry', 'not demanding': 'Angry',\n",
        "        'not deserve': 'Angry', 'not deserving': 'Angry', 'not expect': 'Angry', 'not expecting': 'Angry',\n",
        "        'not fail': 'Happy', 'not failing': 'Happy', 'not get': 'Sad', 'not getting': 'Sad',\n",
        "        'not hesitate': 'Sad', 'not hesitating': 'Sad', 'not hurry': 'Happy', 'not hurrying': 'Happy',\n",
        "        'not intend': 'Sad', 'not intending': 'Sad', 'not learn': 'Angry', 'not learning': 'Angry',\n",
        "        'not liking': 'Angry', 'not loving': 'Sad', 'not manage': 'Angry', 'not managing': 'Angry',\n",
        "        'not neglect': 'Sad', 'not neglecting': 'Sad', 'not offer': 'Angry', 'not offering': 'Angry',\n",
        "        'not plan': 'Angry', 'not planing': 'Angry', 'not prepare': 'Angry', 'not preparing': 'Angry',\n",
        "        'not pretend': 'Angry', 'not pretending': 'Angry', 'not proceed': 'Angry', 'not proceeding': 'Angry',\n",
        "        'not propose': 'Angry', 'not proposing': 'Sad', 'not refuse': 'Sad', 'not refusing': 'Sad',\n",
        "        'not start': 'Sad', 'not starting': 'Sad', 'not stop': 'Happy', 'not stopping': 'Happy',\n",
        "        'not struggle': 'Angry', 'not struggling': 'Angry', 'not swear': 'Angry', 'not swearing': 'Angry',\n",
        "        'not threaten': 'Happy', 'not threatening': 'Happy', 'not try': 'Angry', 'not trying': 'Angry',\n",
        "        'not volunteer': 'Angry', 'not volunteering': 'Angry', 'not wait': 'Angry', 'not waiting': 'Angry',\n",
        "        'not feel': 'Sad', 'not feeling': 'Sad', \"not able\": \"Sad\", \"not do\": \"Sad\",\n",
        "        'not apologize': 'Sad', 'not apologizing': 'Sad', 'not forgive': 'Angry', 'not forgiving': 'Angry',\n",
        "        'not trust': 'Angry', 'not trusting': 'Angry', 'not regret': 'Angry', 'not regretting': 'Angry',\n",
        "        'not rejoice': 'Sad', 'not rejoicing': 'Sad', 'not admire': 'Sad', 'not admiring': 'Sad',\n",
        "        'not compliment': 'Sad', 'not complimenting': 'Sad', 'not criticize': 'Happy', 'not criticizing': 'Happy',\n",
        "        'not encourage': 'Angry', 'not encouraging': 'Angry', 'not insult': 'Sad', 'not insulting': 'Sad',\n",
        "        'not praise': 'Angry', 'not praising': 'Angry', 'not support': 'Angry', 'not supporting': 'Angry',\n",
        "        'not blame': 'Sad', 'not blaming': 'Sad', 'not defend': 'Sad', 'not defending': 'Sad',\n",
        "        'not appreciate': 'Sad', 'not appreciating': 'Sad', 'not enjoy': 'Sad', 'not enjoying': 'Sad',\n",
        "        'not like': 'Angry', 'not liking': 'Angry', 'not love': 'Sad', 'not loving': 'Sad',\n",
        "        'not prefer': 'Sad', 'not preferring': 'Sad', 'not want': 'Angry', 'not wanting': 'Sad',\n",
        "        'not believe': 'Angry', 'not believing': 'Angry', 'not doubt': 'Happy', 'not doubting': 'Happy',\n",
        "        'not imagine': 'Sad', 'not imagining': 'Sad', 'not realize': 'Sad', 'not realizing': 'Sad',\n",
        "        'not remember': 'Sad', 'not remembering': 'Sad', 'not recognize': 'Sad', 'not recognizing': 'Sad',\n",
        "        'not consider': 'Sad', 'not considering': 'Sad', 'not think': 'Sad', 'not thinking': 'Sad',\n",
        "        'not forget': 'Angry', 'not forgetting': 'Angry', 'not ignore': 'Angry', 'not ignoring': 'Angry',\n",
        "        'not overlook': 'Angry', 'not overlooking': 'Angry', 'not understand': 'Sad', 'not understanding': 'Sad',\n",
        "        'not hear': 'Angry', 'not hearing': 'Angry', 'not listen': 'Angry', 'not listening': 'Angry',\n",
        "        'not look': 'Angry', 'not looking': 'Angry', 'not smell': 'Angry', 'not smelling': 'Angry',\n",
        "        'not taste': 'Angry', 'not tasting': 'Angry', 'not touch': 'Angry', 'not touching': 'Angry',\n",
        "        'not feel': 'Sad', 'not feeling': 'Sad', 'not sense': 'Sad', 'not sensing': 'Sad',\n",
        "        'not suppose': 'Angry', 'not supposing': 'Angry', 'not expect': 'Angry', 'not expecting': 'Angry',\n",
        "        'not wait': 'Angry', 'not waiting': 'Angry', 'not long': 'Angry', 'not longing': 'Angry',\n",
        "        'not yearn': 'Angry', 'not yearning': 'Angry', 'not wish': 'Sad', 'not wishing': 'Sad',\n",
        "        'not hope': 'Sad', 'not hoping': 'Sad', 'not desire': 'Sad', 'not desiring': 'Sad',\n",
        "        'not miss': 'Angry', 'not missing': 'Angry', 'not need': 'Angry', 'not needing': 'Angry',\n",
        "        'not want': 'Angry', 'not wanting': 'Sad', 'not require': 'Angry', 'not requiring': 'Angry',\n",
        "        'not demand': 'Angry', 'not demanding': 'Angry', 'not insist': 'Angry', 'not insisting': 'Angry',\n",
        "        'not force': 'Angry', 'not forcing': 'Angry', 'not push': 'Angry', 'not pushing': 'Angry',\n",
        "        'not pull': 'Angry', 'not pulling': 'Angry', 'not drag': 'Angry', 'not dragging': 'Angry',\n",
        "        'not carry': 'Angry', 'not carrying': 'Angry', 'not lift': 'Angry', 'not lifting': 'Angry',\n",
        "        'not drop': 'Angry', 'not dropping': 'Angry', 'not throw': 'Angry', 'not throwing': 'Angry',\n",
        "        'not catch': 'Angry', 'not catching': 'Angry', 'not capture': 'Angry', 'not capturing': 'Angry',\n",
        "        'not grab': 'Angry', 'not grabbing': 'Angry', 'not touch': 'Angry', 'not touching': 'Angry',\n",
        "        'not reach': 'Angry', 'not reaching': 'Angry', 'not approach': 'Angry', 'not approaching': 'Angry',\n",
        "        'not avoid': 'Angry', 'not avoiding': 'Angry', 'not evade': 'Angry', 'not evading': 'Angry',\n",
        "        'not elude': 'Angry', 'not eluding': 'Angry', 'not escape': 'Angry', 'not escaping': 'Angry',\n",
        "        'not run': 'Angry', 'not running': 'Angry', 'not jog': 'Angry', 'not jogging': 'Angry',\n",
        "        'not walk': 'Angry', 'not walking': 'Angry', 'not crawl': 'Angry', 'not crawling': 'Angry',\n",
        "        'not sneak': 'Angry', 'not sneaking': 'Angry', 'not tiptoe': 'Angry', 'not tiptoeing': 'Angry',\n",
        "        'not dance': 'Angry', 'not dancing': 'Angry', 'not stomp': 'Angry', 'not stomping': 'Angry',\n",
        "        'not shake': 'Angry', 'not shaking': 'Angry', 'not tremble': 'Angry', 'not trembling': 'Angry',\n",
        "        'not shiver': 'Angry', 'not shivering': 'Angry', 'not quiver': 'Angry', 'not quivering': 'Angry',\n",
        "        'not vibrate': 'Angry', 'not vibrating': 'Angry', 'not pulsate': 'Angry', 'not pulsating': 'Angry',\n",
        "        'not throb': 'Angry', 'not throbbing': 'Angry', 'not beat': 'Angry', 'not beating': 'Angry',\n",
        "        'not palpitate': 'Angry', 'not palpitating': 'Angry', 'not pump': 'Angry', 'not pumping': 'Angry',\n",
        "        'not glide': 'Angry', 'not gliding': 'Angry', 'not slide': 'Angry', 'not sliding': 'Angry',\n",
        "        'not slip': 'Angry', 'not slipping': 'Angry', 'not skid': 'Angry'\n",
        "}\n",
        "\n",
        "shortcuts = {\n",
        "    'u': 'you', 'y': 'why', 'r': 'are', 'doin': 'doing', 'hw': 'how', 'k': 'okay', 'm': 'am',\n",
        "    'b4': 'before',\n",
        "                   'idc': \"i do not care\", 'ty': 'thank you', 'wlcm': 'welcome', 'bc': 'because', '<3': 'love',\n",
        "                   'xoxo': 'love',\n",
        "                   'ttyl': 'talk to you later', 'gr8': 'great', 'bday': 'birthday', 'awsm': 'awesome', 'gud': 'good',\n",
        "                   'h8': 'hate',\n",
        "                   'lv': 'love', 'dm': 'direct message', 'rt': 'retweet', 'wtf': 'hate', 'idgaf': 'hate',\n",
        "                   'irl': 'in real life', 'yolo': 'you only live once', \"don't\": \"do not\", 'g8': 'great',\n",
        "                   \"won't\": \"will not\", 'tbh': 'to be honest', 'caj': 'casual', 'Ikr': 'I know, right?',\n",
        "                   'omw': 'on my way',\n",
        "                   'ofc': 'of course', 'Idc': \"I don't care\", 'Irl': 'In real life', 'tbf': 'To be fair',\n",
        "                   'obvs': 'obviously', 'v': 'very', 'atm': 'at the moment',\n",
        "                   'col': 'crying out loud', 'gbu': 'god bless you', 'gby': 'god bless you', 'gotcha': 'I got you',\n",
        "                   'hehe': 'laughing', 'haha': 'laughing', 'hf': 'have fun',\n",
        "                   'hry': 'hurry', 'hw': 'hardwork', 'idc': 'i don’t care', 'ikr': 'i know right', 'k': 'ok',\n",
        "                   'lmao': 'laughing my ass off', 'lol': 'laughing out loud',\n",
        "                   'n1': 'nice one', 'na': 'not available', 'qt': 'cutie', 'qtpi': 'cutie pie',\n",
        "                   'rip': 'rest in peace',\n",
        "                   'sry': 'sorry', 'tc': 'take care',\n",
        "                   'thnks': 'thanks', 'thx': 'thanks', 'thnk': 'thanks', 'ttyl': 'talk to you later', 'txt': 'text',\n",
        "                   'ugh': 'disgusted', 'w8': 'wait', \"not sad\": \"happy\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTfaCIzdCLPA"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpImxOjQMxJG"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/content/final_dataset.csv\", header = None)\n",
        "X = dataset[0].values\n",
        "y = dataset[1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGeMIe5zJaKJ",
        "outputId": "0396c25f-7e4a-4944-872a-7dda7ab44fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19999\n",
            "['anger' 'fear' 'joy' 'love' 'sadness' 'surprise']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "emotions = le.inverse_transform([0,1,2,3,4,5])\n",
        "print(len(y))\n",
        "print(emotions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qekztq71CixT"
      },
      "source": [
        "### Cleaning Texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjtkHUzt7k7F"
      },
      "outputs": [],
      "source": [
        "def remove_contradictions(text):\n",
        "    if \"n't\" in text:\n",
        "        text = text.replace(\"n't\", \" not\")\n",
        "    for pattern, replacement in contractions.items():\n",
        "        text = re.sub(pattern, replacement, text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67PUcLrq8OOC"
      },
      "outputs": [],
      "source": [
        "def removing_not(text):\n",
        "        f = re.findall(\"not\\s\\w+\", text)\n",
        "        for i in f:\n",
        "            try:\n",
        "                text = text.replace(i, nots[i])\n",
        "            except:\n",
        "                pass\n",
        "        text = text.lower()\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoA-h2Kr8u_4"
      },
      "outputs": [],
      "source": [
        "def removing_shortcuts(text):\n",
        "    full_words = []\n",
        "\n",
        "    for token in text:\n",
        "        if token in shortcuts.keys():\n",
        "            token = shortcuts[token]\n",
        "        full_words.append(token)\n",
        "    text = \" \".join(full_words)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtNNWZCk_AZ3"
      },
      "outputs": [],
      "source": [
        "def removing_stopwords(text):\n",
        "    return [word for word in text if not word in stop_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDs887QKNctr"
      },
      "outputs": [],
      "source": [
        "corpus = []\n",
        "for i in X:\n",
        "  review = re.sub(\"[^a-zA-Z]\",\" \",i)\n",
        "  review = review.lower()\n",
        "  review = re.sub(r'http\\S+|www.\\S+', '', review)\n",
        "  review = remove_contradictions(review)\n",
        "  review = removing_not(review)\n",
        "  review = review.split()\n",
        "  review = removing_shortcuts(review)\n",
        "  review = ' '.join([i for i in review.split() if not i.isdigit()])\n",
        "  review = word_tokenize(review)\n",
        "  review = removing_stopwords(review)\n",
        "  lemma = WordNetLemmatizer()\n",
        "  review = [lemma.lemmatize(word) for word in review]\n",
        "  review = \" \".join(review)\n",
        "  corpus.append(review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLqmAkANCp1-"
      },
      "source": [
        "### Creating the Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEUeuJkEfpXT",
        "outputId": "3e29442c-af80-413e-873f-5bb8697786a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19999 2000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(max_features=2000)\n",
        "X = cv.fit_transform(corpus).toarray()\n",
        "print(len(X),len(X[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH_VjgPzC2cd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiFLzVA0t8Fd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification Models"
      ],
      "metadata": {
        "id": "0Jv-jxOkW8dh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP Model"
      ],
      "metadata": {
        "id": "uKwiZfGgPfVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "MLP_classifier = MLPClassifier(max_iter = 1000)\n",
        "MLP_classifier.fit(X_train, y_train)\n",
        "y_pred = MLP_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DmP8hCRPefN",
        "outputId": "4a4cffae-ac8f-421a-cb2f-bbb35826fd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 81.5711%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.75      0.74      0.74       683\n",
            "        fear       0.77      0.77      0.77       520\n",
            "       happy       0.85      0.86      0.86      1579\n",
            "        love       0.74      0.73      0.74       303\n",
            "     sadness       0.85      0.85      0.85      1403\n",
            "    surprise       0.70      0.71      0.70       184\n",
            "\n",
            "    accuracy                           0.82      4672\n",
            "   macro avg       0.78      0.78      0.78      4672\n",
            "weighted avg       0.82      0.82      0.82      4672\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GB Model"
      ],
      "metadata": {
        "id": "luKHj-NxP1y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GB_classifier = GradientBoostingClassifier()\n",
        "GB_classifier.fit(X_train, y_train)\n",
        "y_pred = GB_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMhKOC5mPvx8",
        "outputId": "7009d8bc-1664-4808-9c91-decd6758ec4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 78.5745%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.91      0.64      0.75       683\n",
            "        fear       0.89      0.73      0.80       520\n",
            "       happy       0.67      0.94      0.79      1579\n",
            "        love       0.80      0.71      0.76       303\n",
            "     sadness       0.92      0.71      0.80      1403\n",
            "    surprise       0.77      0.79      0.78       184\n",
            "\n",
            "    accuracy                           0.79      4672\n",
            "   macro avg       0.83      0.76      0.78      4672\n",
            "weighted avg       0.82      0.79      0.79      4672\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2Ia3WU9yCHS"
      },
      "source": [
        "### LightGBM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyA0qdz_yKZT",
        "outputId": "c0fcdd11-1e3c-4208-9b6c-08eb0cb08644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138465 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3641\n",
            "[LightGBM] [Info] Number of data points in the train set: 18688, number of used features: 1342\n",
            "[LightGBM] [Info] Start training from score -1.892919\n",
            "[LightGBM] [Info] Start training from score -2.173169\n",
            "[LightGBM] [Info] Start training from score -1.088603\n",
            "[LightGBM] [Info] Start training from score -2.635212\n",
            "[LightGBM] [Info] Start training from score -1.237417\n",
            "[LightGBM] [Info] Start training from score -3.296051\n",
            "Accuracy = 84.0539%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.79      0.77      0.78       683\n",
            "        fear       0.85      0.81      0.83       520\n",
            "       happy       0.82      0.89      0.85      1579\n",
            "        love       0.77      0.82      0.79       303\n",
            "     sadness       0.90      0.85      0.88      1403\n",
            "    surprise       0.83      0.70      0.76       184\n",
            "\n",
            "    accuracy                           0.84      4672\n",
            "   macro avg       0.83      0.81      0.82      4672\n",
            "weighted avg       0.84      0.84      0.84      4672\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "LGBM_classifier = LGBMClassifier()\n",
        "LGBM_classifier.fit(X_train, y_train)\n",
        "y_pred = LGBM_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw1PvphwsBZy"
      },
      "source": [
        "### CatBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj3N72ZqsP0v",
        "outputId": "0ec0cf79-aec6-410b-fa74-82647b700234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 84.8673%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.88      0.75      0.81       683\n",
            "        fear       0.85      0.81      0.83       520\n",
            "       happy       0.80      0.92      0.86      1579\n",
            "        love       0.82      0.70      0.76       303\n",
            "     sadness       0.91      0.87      0.89      1403\n",
            "    surprise       0.83      0.73      0.78       184\n",
            "\n",
            "    accuracy                           0.85      4672\n",
            "   macro avg       0.85      0.80      0.82      4672\n",
            "weighted avg       0.85      0.85      0.85      4672\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "CB_classifier = CatBoostClassifier(logging_level='Silent')\n",
        "CB_classifier.fit(X_train, y_train)\n",
        "y_pred = CB_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umluhHe8riQ0"
      },
      "source": [
        "### XGBoost Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vpbR4syrsoK",
        "outputId": "5c78013d-eced-4db2-ffb9-e60df4a4c8dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 84.8887%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.87      0.77      0.82       683\n",
            "        fear       0.87      0.82      0.84       520\n",
            "       happy       0.81      0.90      0.85      1579\n",
            "        love       0.76      0.83      0.80       303\n",
            "     sadness       0.92      0.85      0.88      1403\n",
            "    surprise       0.79      0.77      0.78       184\n",
            "\n",
            "    accuracy                           0.85      4672\n",
            "   macro avg       0.84      0.82      0.83      4672\n",
            "weighted avg       0.85      0.85      0.85      4672\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "XGBC_classifier = XGBClassifier()\n",
        "XGBC_classifier.fit(X_train, y_train)\n",
        "y_pred = XGBC_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extra Trees Model"
      ],
      "metadata": {
        "id": "_9CGgYznQCpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "ET_classifier = ExtraTreesClassifier()\n",
        "ET_classifier.fit(X_train, y_train)\n",
        "y_pred = ET_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR-JmuzHP91R",
        "outputId": "1fcd36d2-5287-4390-8798-b9ee1ef2260c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 84.9101%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.79      0.80      0.79       683\n",
            "        fear       0.82      0.82      0.82       520\n",
            "       happy       0.89      0.86      0.88      1579\n",
            "        love       0.77      0.78      0.77       303\n",
            "     sadness       0.88      0.89      0.88      1403\n",
            "    surprise       0.75      0.80      0.77       184\n",
            "\n",
            "    accuracy                           0.85      4672\n",
            "   macro avg       0.81      0.83      0.82      4672\n",
            "weighted avg       0.85      0.85      0.85      4672\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhePsbgOPc7_"
      },
      "source": [
        "### Random Forest Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmku0om9Pfy3",
        "outputId": "1dc294cc-f1bf-48fe-ad2c-451b37f76696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 83.7115%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.76      0.82      0.79       683\n",
            "        fear       0.82      0.81      0.81       520\n",
            "       happy       0.89      0.84      0.86      1579\n",
            "        love       0.74      0.78      0.76       303\n",
            "     sadness       0.87      0.87      0.87      1403\n",
            "    surprise       0.73      0.79      0.76       184\n",
            "\n",
            "    accuracy                           0.84      4672\n",
            "   macro avg       0.80      0.82      0.81      4672\n",
            "weighted avg       0.84      0.84      0.84      4672\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest_classifier = RandomForestClassifier()\n",
        "random_forest_classifier.fit(X_train, y_train)\n",
        "y_pred = random_forest_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywlNibWMPYcf"
      },
      "source": [
        "### Decision Tree Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUcAwOfaPblX",
        "outputId": "53acdf96-3ae5-4441-fd86-7b4275ac1c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 79.0882%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.69      0.82      0.75       683\n",
            "        fear       0.79      0.79      0.79       520\n",
            "       happy       0.86      0.74      0.79      1579\n",
            "        love       0.69      0.77      0.73       303\n",
            "     sadness       0.82      0.84      0.83      1403\n",
            "    surprise       0.69      0.79      0.74       184\n",
            "\n",
            "    accuracy                           0.79      4672\n",
            "   macro avg       0.76      0.79      0.77      4672\n",
            "weighted avg       0.80      0.79      0.79      4672\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_classifier = DecisionTreeClassifier()\n",
        "decision_classifier.fit(X_train, y_train)\n",
        "y_pred = decision_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1y31i1uPRHO"
      },
      "source": [
        "### Logistic Regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hImOl32HPVpW",
        "outputId": "a60c6a1a-5b54-422f-c3c9-57e1ad263db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 84.6104%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.81      0.78      0.79       683\n",
            "        fear       0.86      0.79      0.83       520\n",
            "       happy       0.85      0.89      0.87      1579\n",
            "        love       0.79      0.72      0.76       303\n",
            "     sadness       0.86      0.89      0.88      1403\n",
            "    surprise       0.86      0.70      0.77       184\n",
            "\n",
            "    accuracy                           0.85      4672\n",
            "   macro avg       0.84      0.80      0.82      4672\n",
            "weighted avg       0.85      0.85      0.84      4672\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_classifier = LogisticRegression(max_iter = 1000)\n",
        "logistic_classifier.fit(X_train, y_train)\n",
        "y_pred = logistic_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wZiSMbCPxqZ"
      },
      "source": [
        "### Kernal SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck60nqZfP0iJ",
        "outputId": "45a5e115-9327-488d-8117-ce30d3c9fc5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 81.7637%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.84      0.68      0.75       683\n",
            "        fear       0.83      0.75      0.79       520\n",
            "       happy       0.79      0.92      0.85      1579\n",
            "        love       0.86      0.56      0.68       303\n",
            "     sadness       0.83      0.89      0.86      1403\n",
            "    surprise       0.90      0.53      0.67       184\n",
            "\n",
            "    accuracy                           0.82      4672\n",
            "   macro avg       0.84      0.72      0.77      4672\n",
            "weighted avg       0.82      0.82      0.81      4672\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "kernal_classifier = SVC(kernel = 'rbf')\n",
        "kernal_classifier.fit(X_train, y_train)\n",
        "y_pred = kernal_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S9YgOoGPqwB"
      },
      "source": [
        "### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Fkb_AZPsCR",
        "outputId": "6fad6f9a-8909-460d-b24e-2114214d9a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 83.3904%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.77      0.78      0.78       683\n",
            "        fear       0.84      0.81      0.82       520\n",
            "       happy       0.84      0.87      0.86      1579\n",
            "        love       0.76      0.75      0.76       303\n",
            "     sadness       0.87      0.86      0.87      1403\n",
            "    surprise       0.80      0.72      0.76       184\n",
            "\n",
            "    accuracy                           0.83      4672\n",
            "   macro avg       0.81      0.80      0.81      4672\n",
            "weighted avg       0.83      0.83      0.83      4672\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_classifier = SVC(kernel = 'linear')\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzLv2ypNPjKI"
      },
      "source": [
        "### K-Nearest Neighbors (K-NN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knZpS609PnmA",
        "outputId": "1bdd8380-3f42-4e19-d50f-048c69574182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 53.8527%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.41      0.60      0.49       683\n",
            "        fear       0.50      0.42      0.46       520\n",
            "       happy       0.63      0.59      0.61      1579\n",
            "        love       0.51      0.28      0.37       303\n",
            "     sadness       0.55      0.59      0.57      1403\n",
            "    surprise       0.49      0.21      0.30       184\n",
            "\n",
            "    accuracy                           0.54      4672\n",
            "   macro avg       0.52      0.45      0.46      4672\n",
            "weighted avg       0.55      0.54      0.53      4672\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "K_nearest_classifier = KNeighborsClassifier()\n",
        "K_nearest_classifier.fit(X_train, y_train)\n",
        "y_pred = K_nearest_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xif2Y8aIPJen"
      },
      "source": [
        "### Naive Bayes model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txEmfSZiPO6m",
        "outputId": "eb5f7453-7d7a-4957-cd39-24fb53afb193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 37.7140%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.53      0.42      0.47       683\n",
            "        fear       0.30      0.52      0.38       520\n",
            "       happy       0.84      0.30      0.44      1579\n",
            "        love       0.18      0.70      0.28       303\n",
            "     sadness       0.82      0.29      0.43      1403\n",
            "    surprise       0.11      0.60      0.19       184\n",
            "\n",
            "    accuracy                           0.38      4672\n",
            "   macro avg       0.46      0.47      0.37      4672\n",
            "weighted avg       0.66      0.38      0.42      4672\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "naive_classifier = GaussianNB()\n",
        "naive_classifier.fit(X_train,y_train)\n",
        "y_pred = naive_classifier.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Voting Classifier Model"
      ],
      "metadata": {
        "id": "eEra42zRmJUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "MLP_classifier = MLPClassifier(max_iter = 1000)\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GB_classifier = GradientBoostingClassifier()\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "LGBM_classifier = LGBMClassifier()\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "XGBC_classifier = XGBClassifier()\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "ET_classifier = ExtraTreesClassifier()\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest_classifier = RandomForestClassifier()\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_classifier = DecisionTreeClassifier()\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_classifier = LogisticRegression(max_iter = 1000)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "kernal_classifier = SVC(kernel = 'rbf')\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "svm_classifier = SVC(kernel = 'linear')\n",
        "\n",
        "\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('MLPC', MLP_classifier),\n",
        "        ('GBC', GB_classifier),\n",
        "        ('LGBMC', LGBM_classifier),\n",
        "        ('XGBC', XGBC_classifier),\n",
        "        ('ETC', ET_classifier),\n",
        "        ('RFC', random_forest_classifier),\n",
        "        ('DTC', decision_classifier),\n",
        "        ('LC', logistic_classifier),\n",
        "        ('KSVMC', kernal_classifier),\n",
        "        ('SVMC', svm_classifier)\n",
        "        ],\n",
        "    voting='hard')\n",
        "ensemble.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "XdHhq03TmO4R",
        "outputId": "142795db-53c3-4a6b-f599-71dbff27c2aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.191238 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3167\n",
            "[LightGBM] [Info] Number of data points in the train set: 15999, number of used features: 1188\n",
            "[LightGBM] [Info] Start training from score -1.998721\n",
            "[LightGBM] [Info] Start training from score -2.129620\n",
            "[LightGBM] [Info] Start training from score -1.086868\n",
            "[LightGBM] [Info] Start training from score -2.497170\n",
            "[LightGBM] [Info] Start training from score -1.237812\n",
            "[LightGBM] [Info] Start training from score -3.324174\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('MLPC', MLPClassifier(max_iter=1000)),\n",
              "                             ('GBC', GradientBoostingClassifier()),\n",
              "                             ('LGBMC', LGBMClassifier()),\n",
              "                             ('XGBC',\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            featu...\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=None, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=None, ...)),\n",
              "                             ('ETC', ExtraTreesClassifier()),\n",
              "                             ('RFC', RandomForestClassifier()),\n",
              "                             ('DTC', DecisionTreeClassifier()),\n",
              "                             ('LC', LogisticRegression(max_iter=1000)),\n",
              "                             ('KSVMC', SVC()), ('SVMC', SVC(kernel='linear'))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;MLPC&#x27;, MLPClassifier(max_iter=1000)),\n",
              "                             (&#x27;GBC&#x27;, GradientBoostingClassifier()),\n",
              "                             (&#x27;LGBMC&#x27;, LGBMClassifier()),\n",
              "                             (&#x27;XGBC&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            featu...\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=None, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=None, ...)),\n",
              "                             (&#x27;ETC&#x27;, ExtraTreesClassifier()),\n",
              "                             (&#x27;RFC&#x27;, RandomForestClassifier()),\n",
              "                             (&#x27;DTC&#x27;, DecisionTreeClassifier()),\n",
              "                             (&#x27;LC&#x27;, LogisticRegression(max_iter=1000)),\n",
              "                             (&#x27;KSVMC&#x27;, SVC()), (&#x27;SVMC&#x27;, SVC(kernel=&#x27;linear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;MLPC&#x27;, MLPClassifier(max_iter=1000)),\n",
              "                             (&#x27;GBC&#x27;, GradientBoostingClassifier()),\n",
              "                             (&#x27;LGBMC&#x27;, LGBMClassifier()),\n",
              "                             (&#x27;XGBC&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            featu...\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=None, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=None, ...)),\n",
              "                             (&#x27;ETC&#x27;, ExtraTreesClassifier()),\n",
              "                             (&#x27;RFC&#x27;, RandomForestClassifier()),\n",
              "                             (&#x27;DTC&#x27;, DecisionTreeClassifier()),\n",
              "                             (&#x27;LC&#x27;, LogisticRegression(max_iter=1000)),\n",
              "                             (&#x27;KSVMC&#x27;, SVC()), (&#x27;SVMC&#x27;, SVC(kernel=&#x27;linear&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>MLPC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GBC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LGBMC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>XGBC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>ETC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ExtraTreesClassifier</label><div class=\"sk-toggleable__content\"><pre>ExtraTreesClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>RFC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>DTC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>KSVMC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVMC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ensemble.predict(X_test)\n",
        "print(f\"Accuracy = {accuracy_score(y_test, y_pred)*100:2.4f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=emotions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEoN1pM-mUmK",
        "outputId": "07d5380f-296b-49aa-c765-ab5fd3190a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 89.1250%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.88      0.90      0.89       541\n",
            "        fear       0.85      0.86      0.85       471\n",
            "         joy       0.90      0.93      0.91      1364\n",
            "        love       0.82      0.76      0.79       324\n",
            "     sadness       0.94      0.92      0.93      1157\n",
            "    surprise       0.77      0.69      0.73       143\n",
            "\n",
            "    accuracy                           0.89      4000\n",
            "   macro avg       0.86      0.84      0.85      4000\n",
            "weighted avg       0.89      0.89      0.89      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "rieLW7GNKei2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = [['Neural Network :', MLPClassifier(max_iter = 1000)],\n",
        "               ['GradientBoostingClassifier: ', GradientBoostingClassifier()],\n",
        "               ['LGBM_classifier: ', LGBMClassifier()],\n",
        "               ['CatBoost :', CatBoostClassifier(logging_level='Silent')],\n",
        "               ['XGB :', XGBClassifier()],\n",
        "               ['ExtraTreesClassifier :', ExtraTreesClassifier()],\n",
        "               ['RandomForest :',RandomForestClassifier()],\n",
        "               ['DecisionTree :',DecisionTreeClassifier()],\n",
        "               ['LogisticRegression :', LogisticRegression(max_iter = 1000)],\n",
        "               ['Kernel SVM :', SVC(kernel = 'rbf')],\n",
        "               ['Linear SVM :', SVC(kernel = \"linear\")],\n",
        "               ['SVM :', SVC()],\n",
        "               ['KNeighbours :', KNeighborsClassifier()],\n",
        "               ['Naive Bayes :', GaussianNB()],\n",
        "               ['AdaBoostClassifier :', AdaBoostClassifier()],\n",
        "               ]\n",
        "\n",
        "for name,classifier in classifiers:\n",
        "    classifier = classifier\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    print(name, accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV8L3a7eSyZJ",
        "outputId": "cbf2c6f4-8fe6-4f39-a464-233564f45bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network : 0.84775\n",
            "GradientBoostingClassifier:  0.847\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.119011 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3167\n",
            "[LightGBM] [Info] Number of data points in the train set: 15999, number of used features: 1188\n",
            "[LightGBM] [Info] Start training from score -1.998721\n",
            "[LightGBM] [Info] Start training from score -2.129620\n",
            "[LightGBM] [Info] Start training from score -1.086868\n",
            "[LightGBM] [Info] Start training from score -2.497170\n",
            "[LightGBM] [Info] Start training from score -1.237812\n",
            "[LightGBM] [Info] Start training from score -3.324174\n",
            "LGBM_classifier:  0.87775\n",
            "CatBoost : 0.88925\n",
            "XGB : 0.89275\n",
            "ExtraTreesClassifier : 0.88475\n",
            "RandomForest : 0.8765\n",
            "DecisionTree : 0.83725\n",
            "LogisticRegression : 0.884\n",
            "Kernel SVM : 0.83575\n",
            "Linear SVM : 0.868\n",
            "SVM : 0.83575\n",
            "KNeighbours : 0.573\n",
            "Naive Bayes : 0.395\n",
            "AdaBoostClassifier : 0.362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JilrBBRzsbyA"
      },
      "source": [
        "## Predict Single Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39hpX8mboYBc"
      },
      "outputs": [],
      "source": [
        "def predict_emotion(text, classifier):\n",
        "  text = text.replace(\"\\n\",\" \")\n",
        "  review = re.sub(\"[^a-zA-Z]\",\" \",text)\n",
        "  review = review.lower()\n",
        "  review = re.sub(r'http\\S+|www.\\S+', '', review)\n",
        "  review = remove_contradictions(review)\n",
        "  review = removing_not(review)\n",
        "  review = review.split()\n",
        "  review = removing_shortcuts(review)\n",
        "  review = ' '.join([i for i in review.split() if not i.isdigit()])\n",
        "  review = word_tokenize(review)\n",
        "  review = removing_stopwords(review)\n",
        "  lemma = WordNetLemmatizer()\n",
        "  review = [lemma.lemmatize(word) for word in review]\n",
        "  review = \" \".join(review)\n",
        "  test = cv.transform([review]).toarray()\n",
        "  result = classifier.predict(test)\n",
        "  result = le.inverse_transform(result)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "JBU25PLVsqnb",
        "outputId": "21cac22f-2574-4580-e6a3-a032327e1ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['joy']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFittedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2a68451ac5da>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGB_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLGBM_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_emotion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCB_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-bd655e7e084a>\u001b[0m in \u001b[0;36mpredict_emotion\u001b[0;34m(text, classifier)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \"\"\"\n\u001b[0;32m-> 1308\u001b[0;31m         \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m         \u001b[0mencoded_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_prediction_to_decision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1262\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         )\n\u001b[0;32m-> 1264\u001b[0;31m         \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_raw_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raw_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;34m\"\"\"Return the sum of the trees raw predictions (+ init estimator).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_predict_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0mpredict_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_raw_predict_init\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_raw_predict_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;34m\"\"\"Check input and compute raw predictions of the init estimator.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"zero\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_check_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;34m\"\"\"Check that the estimator is initialized, raising an error if not.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFittedError\u001b[0m: This GradientBoostingClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ],
      "source": [
        "text = '''I am not happy to see you here .'''\n",
        "\n",
        "print(predict_emotion(text, ensemble))\n",
        "print(predict_emotion(text, GB_classifier))\n",
        "print(predict_emotion(text, LGBM_classifier))\n",
        "print(predict_emotion(text, CB_classifier))\n",
        "print(predict_emotion(text, XGBC_classifier))\n",
        "print(predict_emotion(text, ET_classifier))\n",
        "print(predict_emotion(text, random_forest_classifier))\n",
        "print(predict_emotion(text, decision_classifier))\n",
        "print(predict_emotion(text, K_nearest_classifier))\n",
        "print(predict_emotion(text, kernal_classifier))\n",
        "print(predict_emotion(text, svm_classifier))\n",
        "print(predict_emotion(text, naive_classifier))\n",
        "print(predict_emotion(text, logistic_classifier))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0Jv-jxOkW8dh",
        "eEra42zRmJUh",
        "JilrBBRzsbyA"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}